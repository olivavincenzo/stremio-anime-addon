name: Aggiorna Catalogo Anime

on:
  # Esegue l'azione automaticamente ogni 30 minuti
  schedule:
    - cron: '*/30 * * * *'
  
  # Permette di avviare l'azione manualmente dal tab "Actions" per testare
  workflow_dispatch:

# Permessi necessari per salvare i file generati
permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      # 1. Scarica il codice
      - name: Checkout del codice
        uses: actions/checkout@v4

      # 2. Prepara Python
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' 

      # 3. Installa TUTTE le librerie necessarie
      # Qui ho aggiunto beautifulsoup4 (che è 'bs4') e requests
      - name: Installa librerie
        run: |
          python -m pip install --upgrade pip
          pip install cloudscraper beautifulsoup4 requests

      # 4. Esegue il tuo script
      - name: Esegui lo scraper
        run: python builder.py

      # 5. Salva i nuovi file (manifest.json e il catalogo) e li carica su GitHub
      - name: Commit e Push dei nuovi dati
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add .
          # Il comando sotto prova a fare commit, se non ci sono novità non dà errore
          git commit -m "Aggiornamento automatico catalogo" || echo "Nessuna modifica da salvare"
          git push